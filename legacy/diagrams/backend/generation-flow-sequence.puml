@startuml Data Flow Sequence
!theme plain

title JobWise AI Resume Generation - 2-Stage Pipeline Implementation

actor "User" as user
participant "Flutter App" as app
participant "API Gateway" as gateway
participant "Generation Controller" as controller
participant "Generation Service" as service
participant "Analysis & Matching\n(Stage 1)" as stage1
participant "Generation & Validation\n(Stage 2)" as stage2
participant "Mock LLM Service" as llm
participant "Profile Repository" as profile_repo
participant "Job Repository" as job_repo
participant "Generation Repository" as gen_repo
database "Database" as db

== Resume Generation Request ==

user -> app: Request resume generation\nfor selected job
app -> gateway: POST /api/v1/generations/resume\n{profile_id, job_id, options}
gateway -> controller: Route to generation endpoint
controller -> service: start_resume_generation(request)

service -> profile_repo: get_profile(profile_id)
profile_repo -> db: SELECT profile data
profile_repo <-- db: MasterProfile entity
service <-- profile_repo: Complete profile

service -> job_repo: get_job(job_id)
job_repo -> db: SELECT job data
job_repo <-- db: Job entity
service <-- job_repo: JobPosting

service -> gen_repo: create_generation(user_id, profile_id, job_id)
gen_repo -> db: INSERT generation record
service <-- gen_repo: Generation entity (status: pending)

controller <-- service: GenerationResponse (status: pending)
gateway <-- controller: HTTP 201 Created
app <-- gateway: Generation created with id
user <-- app: Show "Generation started..."

== Background 2-Stage Pipeline ==

service -> service: start_background_pipeline(generation_id)

== Stage 1: Analysis & Matching (40% - 3s) ==

service -> gen_repo: update_stage(generation_id, 1, "Analysis & Matching")
service -> stage1: execute_analysis_matching(profile, job)
stage1 -> llm: analyze_job_requirements(job_description)
note right: Extract keywords, requirements,\nseniority level, skills
stage1 <-- llm: Job analysis result (2500 tokens)
stage1 -> llm: match_profile_content(profile, job_analysis)  
note right: Score experiences/projects by\nrelevance (0.0-1.0)
stage1 <-- llm: Content matching result (2500 tokens)
service <-- stage1: AnalysisMatchingResult\n{job_requirements, scored_content}

== Stage 2: Generation & Validation (100% - 5s) ==

service -> gen_repo: update_stage(generation_id, 2, "Generation & Validation")
service -> stage2: execute_generation_validation(matched_content, job_analysis)
stage2 -> llm: generate_tailored_resume(scored_content, requirements)
note right: Generate resume using ONLY\ntop-scored user content
stage2 <-- llm: Generated resume (2500 tokens)
stage2 -> llm: validate_quality(generated_resume, job_requirements)
note right: Check ATS compliance,\nkeyword coverage, quality
stage2 <-- llm: Validation result (ATS score, recommendations)
service <-- stage2: GenerationValidationResult\n{resume_content, ats_score, pdf_url}

== Save Completed Generation ==

service -> gen_repo: set_completed(generation_id, result, tokens_used, generation_time)
gen_repo -> db: UPDATE generation\nSET status='completed', result=json
service <-- gen_repo: Updated generation

== Real-time Status Polling ==

loop Every 2 seconds during generation
    user -> app: Check generation status
    app -> gateway: GET /api/v1/generations/{id}
    gateway -> controller: Route status request
    controller -> service: get_generation_status(id)
    service -> gen_repo: get_by_id(generation_id)
    gen_repo -> db: SELECT generation
    service <-- gen_repo: Current generation state
    controller <-- service: Progress update
    gateway <-- controller: Status response
    app <-- gateway: Progress update
    user <-- app: Show progress:\n"Stage 1/2: Analysis & Matching (40%)"
end

== Get Final Result ==

user -> app: View completed generation
app -> gateway: GET /api/v1/generations/{id}/result
gateway -> controller: Route result request  
controller -> service: get_generation_result(id)
service -> gen_repo: get_by_id(generation_id)
service <-- gen_repo: Completed generation with result
controller <-- service: DetailedGenerationResult
gateway <-- controller: HTTP 200 with result
app <-- gateway: Generation result
user <-- app: Show resume content,\nATS score, download links

note over stage1, stage2
**2-Stage Pipeline (Simplified)**
✅ Stage 1: Analysis & Matching (40% weight, ~3s)
  - Job analysis + profile content matching
  - Combined LLM operations for efficiency
  - 2500 tokens per operation (5000 total)

✅ Stage 2: Generation & Validation (60% weight, ~5s)  
  - Content generation + quality validation
  - Combined operations for speed
  - 2500 tokens per operation (5000 total)

**Total**: 2 stages, ~8s, 10000 tokens
**Progress**: [40, 60] weight distribution
end note

note over llm
**Mock LLM Implementation**
✅ **Features**:
- Realistic response timing (3s + 5s)
- Template-based content generation
- ATS score simulation (0.85-0.95)
- Professional resume templates  
- Anti-fabrication constraints

✅ **Error Handling**:
- Rate limiting (10/hour per user)
- Retry logic with exponential backoff
- Graceful degradation scenarios
- Structured error responses
end note

note over db
**Database Schema (Complete)**
✅ **Tables**:
- users (auth working)
- master_profiles (CRUD complete) 
- experiences/education/projects/skills (complete)
- jobs (static + custom working)
- generations (2-stage pipeline support)

✅ **Generation Fields**:
- current_stage: 0-2 (2-stage pipeline)
- total_stages: 2 (default)
- stage_name: "Analysis & Matching" | "Generation & Validation"
- progress calculation: [40, 60] weights
end note

@enduml