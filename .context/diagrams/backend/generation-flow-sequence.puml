@startuml Data Flow Sequence
!theme plain

title JobWise AI Resume Generation - Current Implementation Status (F7-F8 Structure Ready)

actor "User" as user
participant "Flutter App" as app
participant "API Gateway" as gateway
participant "Generation Controller" as controller
participant "Generation Service" as service
participant "AI Orchestrator" as orchestrator
participant "Job Analyzer\n(Stage 1)" as stage1
participant "Profile Compiler\n(Stage 2)" as stage2  
participant "Document Generator\n(Stage 3)" as stage3
participant "Quality Validator\n(Stage 4)" as stage4
participant "Export Handler\n(Stage 5)" as stage5
participant "Mock LLM Service" as llm
participant "Profile Repository" as profile_repo
participant "Job Repository" as job_repo
participant "Job Description Repository" as job_desc_repo
participant "Document Repository" as doc_repo
database "Database\n(F2 Complete)" as db

== F1-F6 Foundation Working ==

note over user, db
    âœ… **F1-F6 Complete Implementation**
    - F1: FastAPI application with middleware, health checks
    - F2: SQLAlchemy async database with single schema approach
    - F3: JWT authentication working (13/13 tests passing)
    - F4: Profile management with full CRUD operations
    - F5: Job discovery with static data (6/6 tests passing)
    - F6: Custom job descriptions with keyword extraction
end note

== Resume Generation Request (F7 Structure Ready) ==

user -> app: âœ… Request resume generation\nfor saved job OR custom job description
app -> gateway: âœ… POST /api/v1/generations/resume\n(API routing working)
gateway -> controller: ðŸš§ Route to generation endpoint\n(Structure ready)
controller -> service: ðŸš§ generate_resume(request)\n(Mock service prepared)

service -> profile_repo: âœ… get_profile(profile_id)\n(F4 working)
profile_repo -> db: âœ… SELECT profile data\n(F2 working)
profile_repo <-- db: âœ… MasterProfile entity
service <-- profile_repo: âœ… Complete profile with experiences

alt Job from static data (F5)
    service -> job_repo: âœ… get_job(job_id)\n(F5 working)
    job_repo -> db: âœ… SELECT job data
    job_repo <-- db: âœ… Job entity  
    service <-- job_repo: âœ… JobPosting
else Custom job description (F6)
    service -> job_desc_repo: âœ… get_job_description(job_desc_id)\n(F6 working)
    job_desc_repo -> db: âœ… SELECT custom job data
    job_desc_repo <-- db: âœ… JobDescription entity
    service <-- job_desc_repo: âœ… Custom JobDescription
end

service -> orchestrator: ðŸš§ execute_pipeline(profile, job, options)\n(F7 mock implementation ready)

== Stage 1: Job Analysis (F7 Mock Ready) ==

orchestrator -> stage1: ðŸš§ execute(JobAnalysisInput)\n(Mock responses prepared)
stage1 -> llm: ðŸš§ **MOCK** analyze_job_requirements(job_description)\n(Realistic timing simulation)
note right: **Mock Prompt**: Extract ATS keywords,\nrequirements, seniority level\n**Timing**: 1.5s realistic simulation
stage1 <-- llm: ðŸš§ **Mock** Analysis result (simulated 1500 tokens)
orchestrator <-- stage1: ðŸš§ JobAnalysisResult\n(Keywords, requirements, skills categories)

== Stage 2: Profile Compilation (F7 Mock Ready) ==

orchestrator -> stage2: ðŸš§ execute(ProfileCompilationInput)\n(F4 profile data + mock AI) 
stage2 -> llm: ðŸš§ **MOCK** score_profile_relevance(profile, job_analysis)\n(Using real F4 profile data)
note right: **Mock Prompt**: Score experiences\nand skills by relevance (0-100)\n**Timing**: 1.2s realistic simulation
stage2 <-- llm: ðŸš§ **Mock** Scoring result (simulated 2000 tokens)
orchestrator <-- stage2: ðŸš§ ProfileCompilationResult\n(Scored experiences, ranked skills, match %)

== Stage 3: Document Generation (F7 Mock Ready) ==

orchestrator -> stage3: ðŸš§ execute(DocumentGenerationInput)\n(Template-based generation)
stage3 -> llm: ðŸš§ **MOCK** generate_tailored_resume(scored_profile, job_reqs)\n(Professional templates ready)
note right: **Mock Prompt**: Generate resume\nfocusing on top-scored content\n**Timing**: 2.5s realistic simulation
stage3 <-- llm: ðŸš§ **Mock** Generated content (simulated 3000 tokens)
orchestrator <-- stage3: ðŸš§ DocumentGenerationResult\n(Resume content, cover letter content)

== Stage 4: Quality Validation (F7 Mock Ready) ==

orchestrator -> stage4: ðŸš§ execute(ValidationInput)\n(ATS compliance simulation)
stage4 -> llm: ðŸš§ **MOCK** validate_quality(generated_content, job_analysis)\n(Quality metrics simulation)
note right: **Mock Prompt**: Check ATS compliance,\nfactuality, keyword coverage\n**Timing**: 1.0s realistic simulation
stage4 <-- llm: ðŸš§ **Mock** Validation result (simulated 1500 tokens)
orchestrator <-- stage4: ðŸš§ ValidationResult\n(ATS score 0.85-0.95, issues, keyword coverage %)

alt Mock quality validation passes
    == Stage 5: Export Ready (F8 Structure Ready) ==
    
    orchestrator -> stage5: ðŸš§ execute(ExportInput)\n(Text export ready)
    stage5 -> stage5: ðŸš§ **MOCK** generate_text_export(content)\n(F8 text export framework)
    note right: **Mock Implementation**: No LLM tokens,\nlocal text formatting\n**Output**: Clean .txt file
    orchestrator <-- stage5: ðŸš§ ExportResult\n(Text file path, download URL)

else Mock quality validation fails
    
    orchestrator -> stage3: ðŸš§ regenerate_with_stricter_prompts()\n(Mock retry logic)
    stage3 -> llm: ðŸš§ **MOCK** regenerate_resume(feedback, constraints)
    stage3 <-- llm: ðŸš§ **Mock** Regenerated content
    orchestrator -> stage4: ðŸš§ validate_again()
    
    alt Still fails after retry
        orchestrator -> orchestrator: ðŸš§ mark_as_needs_review()\n(Error handling ready)
    end
end

service <-- orchestrator: ðŸš§ PipelineResult\n(Mock generation complete)

== Save Results (F2 Database Working) ==

service -> doc_repo: ðŸš§ save_document(generated_document)\n(F8 structure ready)
doc_repo -> db: ðŸš§ INSERT document, metadata\n(DocumentModel defined)
service <-- doc_repo: ðŸš§ Document entity

controller <-- service: ðŸš§ GenerationResponse\n(Mock result with realistic data)
gateway <-- controller: ðŸš§ HTTP 201 Created\n(API response ready)
app <-- gateway: ðŸš§ Generation result with status
user <-- app: ðŸš§ Show generation complete\nwith download link (.txt format)

== Real-time Status Updates (F7 Structure Ready) ==

loop Every 5 seconds during generation
    user -> app: âœ… Check generation status\n(Frontend polling ready)
    app -> gateway: ðŸš§ GET /api/v1/generations/{id}/status\n(Endpoint structure ready)
    gateway -> controller: ðŸš§ Route status request
    controller -> service: ðŸš§ get_generation_status(id)\n(Progress tracking ready)
    controller <-- service: ðŸš§ Current stage and progress\n(5-stage progress simulation)
    gateway <-- controller: ðŸš§ Status response
    app <-- gateway: ðŸš§ Progress update
    user <-- app: ðŸš§ Show progress:\n"Stage 2/5: Compiling Profile (40%)"
end

note over orchestrator
**F7 Mock AI Pipeline Ready**
Total Mock Token Budget: 8000 tokens
âœ… Stage 1: 1500 tokens (Job Analysis) - MOCK READY
âœ… Stage 2: 2000 tokens (Profile Compilation) - MOCK READY  
âœ… Stage 3: 3000 tokens (Document Generation) - MOCK READY
âœ… Stage 4: 1500 tokens (Quality Validation) - MOCK READY
âœ… Stage 5: 0 tokens (Text Export) - F8 STRUCTURE READY

**Performance Target**: <5s mock processing
**Quality**: Realistic mock responses with templates
end note

note over llm
**Mock LLM Implementation Ready**
ðŸš§ **Mock Features**:
- Realistic response timing (1-3s per stage)
- Template-based content generation
- Progressive quality improvement
- ATS score simulation (0.85-0.95)
- Professional resume templates
- Keyword coverage simulation

ðŸš§ **Error Simulation**:
- Occasional quality failures for testing
- Retry logic with improved prompts
- Graceful degradation scenarios
- Rate limiting simulation
end note

note over db
**F2 Database Foundation Complete**
âœ… **Working Tables**:
- users (F3 auth working)
- master_profiles (F4 complete)
- experiences/education/skills (F4 complete)
- jobs (F5 static data working)
- job_descriptions (F6 custom jobs working)
- generations (F7 structure ready)
- documents (F8 structure ready)

âœ… **Features**:
- Async SQLAlchemy operations
- Single schema approach
- API-consistent table naming
- Full relationship mapping
end note

@enduml