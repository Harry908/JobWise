# JobWise Universal Backend Configuration
# This file demonstrates the flexible provider configuration system

# =============================================================================
# CORE APPLICATION SETTINGS
# =============================================================================
APP_NAME="JobWise Universal Backend"
APP_VERSION="1.0.0"
DEBUG=True
SECRET_KEY="your-super-secret-key-here"
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]

# =============================================================================
# DATABASE CONFIGURATION (Universal)
# =============================================================================
# Supports: sqlite, postgresql, mysql
DATABASE_TYPE="sqlite"  # Change to "postgresql" or "mysql" for production
DATABASE_URL="sqlite:///./jobwise.db"
# DATABASE_URL="postgresql://user:password@localhost/jobwise"  # PostgreSQL
# DATABASE_URL="mysql://user:password@localhost/jobwise"       # MySQL

# =============================================================================
# LLM PROVIDER CONFIGURATION (Multi-Provider Support)
# =============================================================================

# Primary LLM Provider (will be used first)
PRIMARY_LLM_PROVIDER="openai_gpt4"  # Options: openai_gpt3_5, openai_gpt4, claude_sonnet, claude_haiku, gemini_pro, gemini_flash, groq_llama3_70b, groq_mixtral_8x7b, azure_openai, local_llama

# LLM Fallback Chain (used when primary fails)
LLM_FALLBACK_CHAIN=["groq_llama3_70b", "claude_sonnet", "gemini_pro", "openai_gpt3_5"]

# OpenAI Configuration
OPENAI_API_KEY="sk-your-openai-api-key-here"
OPENAI_ORG_ID="your-org-id-optional"
OPENAI_DEFAULT_MODEL="gpt-4-turbo-preview"
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7
OPENAI_RATE_LIMIT=60  # requests per minute

# Anthropic Claude Configuration
ANTHROPIC_API_KEY="sk-ant-your-claude-api-key-here"
CLAUDE_DEFAULT_MODEL="claude-3-sonnet-20240229"
CLAUDE_MAX_TOKENS=4000
CLAUDE_TEMPERATURE=0.7
CLAUDE_RATE_LIMIT=50  # requests per minute

# Google Gemini Configuration
GOOGLE_API_KEY="your-google-api-key-here"
GEMINI_DEFAULT_MODEL="gemini-pro"
GEMINI_MAX_TOKENS=4000
GEMINI_TEMPERATURE=0.7
GEMINI_RATE_LIMIT=60  # requests per minute

# Groq Configuration (Ultra-Fast Inference)
GROQ_API_KEY="your-groq-api-key-here"
GROQ_DEFAULT_MODEL="llama3-70b-8192"  # Options: llama3-70b-8192, llama3-8b-8192, mixtral-8x7b-32768, gemma-7b-it
GROQ_MAX_TOKENS=4000
GROQ_TEMPERATURE=0.7
GROQ_RATE_LIMIT=30  # requests per minute (free tier)
GROQ_SPEED_PRIORITY=True  # Optimize for speed over cost

# Azure OpenAI Configuration (Enterprise)
AZURE_OPENAI_API_KEY="your-azure-openai-key-here"
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_DEPLOYMENT="gpt-4-deployment-name"
AZURE_OPENAI_API_VERSION="2024-02-15-preview"

# Local LLM Configuration (Self-hosted)
LOCAL_LLM_MODEL_PATH="/path/to/local/model"
LOCAL_LLM_DEVICE="cuda"  # cuda, cpu, mps (for Apple Silicon)
LOCAL_LLM_MAX_TOKENS=4000

# =============================================================================
# JOB SEARCH PROVIDER CONFIGURATION
# =============================================================================

# Primary Job Search Provider
PRIMARY_JOB_PROVIDER="mock"  # Options: indeed, linkedin, mock, static_json

# Job Search Fallback Chain
JOB_FALLBACK_CHAIN=["indeed", "static_json"]

# Indeed API Configuration
INDEED_API_KEY="your-indeed-api-key-here"
INDEED_RATE_LIMIT=100  # requests per day (free tier)

# LinkedIn API Configuration
LINKEDIN_CLIENT_ID="your-linkedin-client-id"
LINKEDIN_CLIENT_SECRET="your-linkedin-client-secret"
LINKEDIN_RATE_LIMIT=500  # requests per day

# Mock Job Data Configuration
MOCK_JOB_COUNT=1000  # number of mock jobs to generate
MOCK_JOB_UPDATE_INTERVAL=86400  # seconds (24 hours)

# =============================================================================
# PDF GENERATION PROVIDER CONFIGURATION
# =============================================================================

# Primary PDF Provider
PRIMARY_PDF_PROVIDER="reportlab"  # Options: reportlab, weasyprint, cloud_pdf

# PDF Fallback Chain
PDF_FALLBACK_CHAIN=["weasyprint", "reportlab"]

# ReportLab Configuration
REPORTLAB_FONT_PATH="/path/to/fonts"
REPORTLAB_TEMPLATE_PATH="./templates/pdf/reportlab"

# WeasyPrint Configuration
WEASYPRINT_TEMPLATE_PATH="./templates/pdf/weasyprint"
WEASYPRINT_CSS_PATH="./static/css/pdf.css"

# Cloud PDF Service Configuration
CLOUD_PDF_API_KEY="your-cloud-pdf-api-key"
CLOUD_PDF_ENDPOINT="https://api.cloudpdf.com/v1"
CLOUD_PDF_RATE_LIMIT=1000  # requests per month

# =============================================================================
# STORAGE PROVIDER CONFIGURATION
# =============================================================================

# Primary Storage Provider
PRIMARY_STORAGE_PROVIDER="local"  # Options: s3, azure_blob, gcs, local, minio

# Storage Fallback Chain
STORAGE_FALLBACK_CHAIN=["local"]

# AWS S3 Configuration
AWS_ACCESS_KEY_ID="your-aws-access-key"
AWS_SECRET_ACCESS_KEY="your-aws-secret-key"
AWS_S3_BUCKET_NAME="jobwise-documents"
AWS_S3_REGION="us-west-2"

# Azure Blob Storage Configuration
AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=..."
AZURE_STORAGE_CONTAINER="jobwise-documents"

# Google Cloud Storage Configuration
GOOGLE_CLOUD_PROJECT_ID="your-gcp-project-id"
GOOGLE_CLOUD_STORAGE_BUCKET="jobwise-documents"
GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"

# Local File Storage Configuration
LOCAL_STORAGE_PATH="./storage/documents"
LOCAL_STORAGE_MAX_SIZE_GB=10

# =============================================================================
# CACHE PROVIDER CONFIGURATION
# =============================================================================

# Primary Cache Provider
PRIMARY_CACHE_PROVIDER="redis"  # Options: redis, memory, memcached, disk

# Cache Fallback Chain
CACHE_FALLBACK_CHAIN=["memory"]

# Redis Configuration
REDIS_URL="redis://localhost:6379/0"
REDIS_PASSWORD=""
REDIS_MAX_CONNECTIONS=10
REDIS_DEFAULT_TTL=3600  # 1 hour

# Memory Cache Configuration
MEMORY_CACHE_MAX_SIZE=1000  # number of entries
MEMORY_CACHE_DEFAULT_TTL=3600  # 1 hour

# Memcached Configuration
MEMCACHED_SERVERS=["127.0.0.1:11211"]

# Disk Cache Configuration
DISK_CACHE_PATH="./cache"
DISK_CACHE_MAX_SIZE_GB=5

# =============================================================================
# RESILIENCE & MONITORING CONFIGURATION
# =============================================================================

# Circuit Breaker Settings
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5  # failures before opening
CIRCUIT_BREAKER_TIMEOUT_DURATION=60  # seconds to stay open
CIRCUIT_BREAKER_EXPECTED_EXCEPTION="Exception"

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30  # seconds
HEALTH_CHECK_TIMEOUT=10  # seconds
HEALTH_CHECK_ENABLED=True

# Retry Configuration
RETRY_MAX_ATTEMPTS=3
RETRY_BASE_DELAY=1.0  # seconds
RETRY_MAX_DELAY=60.0  # seconds
RETRY_EXPONENTIAL_BASE=2

# Provider Performance Monitoring
PERFORMANCE_MONITORING_ENABLED=True
PERFORMANCE_METRICS_RETENTION_DAYS=30
PERFORMANCE_ALERT_THRESHOLD=5.0  # seconds

# =============================================================================
# COST OPTIMIZATION CONFIGURATION
# =============================================================================

# Cost Optimization Settings
COST_OPTIMIZATION_ENABLED=True
COST_TRACKING_ENABLED=True
DAILY_COST_BUDGET=100.0  # USD
MONTHLY_COST_BUDGET=3000.0  # USD

# Provider Cost Configuration (USD per 1K tokens)
OPENAI_GPT4_COST_PER_1K_TOKENS=0.03
OPENAI_GPT3_5_COST_PER_1K_TOKENS=0.002
CLAUDE_SONNET_COST_PER_1K_TOKENS=0.015
CLAUDE_HAIKU_COST_PER_1K_TOKENS=0.00125
GEMINI_PRO_COST_PER_1K_TOKENS=0.00125
GROQ_LLAMA3_70B_COST_PER_1K_TOKENS=0.00059  # input cost
GROQ_LLAMA3_8B_COST_PER_1K_TOKENS=0.00005   # input cost  
GROQ_MIXTRAL_8X7B_COST_PER_1K_TOKENS=0.00024  # input cost
LOCAL_LLM_COST_PER_1K_TOKENS=0.0001  # electricity/compute cost

# Cost-Based Provider Routing
PREFER_CHEAPER_PROVIDERS=False
COST_PERFORMANCE_RATIO_THRESHOLD=2.0

# =============================================================================
# AI PIPELINE CONFIGURATION
# =============================================================================

# Token Budget Management
TOTAL_TOKEN_BUDGET=8000
STAGE_1_TOKEN_ALLOCATION=1500  # Job Analyzer
STAGE_2_TOKEN_ALLOCATION=2000  # Profile Compiler
STAGE_3_TOKEN_ALLOCATION=3000  # Document Generator
STAGE_4_TOKEN_ALLOCATION=1500  # Quality Validator
STAGE_5_TOKEN_ALLOCATION=0     # PDF Exporter (local processing)

# Generation Quality Thresholds
MIN_ATS_SCORE=0.85
MIN_KEYWORD_COVERAGE=0.90
MAX_GENERATION_TIME=60  # seconds

# Pipeline Timeout Configuration
PIPELINE_TIMEOUT=300  # 5 minutes total
STAGE_TIMEOUT=60  # 1 minute per stage
PROVIDER_SWITCH_TIMEOUT=10  # seconds

# =============================================================================
# RATE LIMITING CONFIGURATION
# =============================================================================

# API Rate Limiting
API_RATE_LIMIT_REQUESTS=100  # per user per hour
AI_GENERATION_LIMIT=10  # per user per hour
GLOBAL_RATE_LIMIT=1000  # requests per minute

# Provider-Specific Rate Limits (overrides global)
OPENAI_USER_RATE_LIMIT=50  # per user per hour
CLAUDE_USER_RATE_LIMIT=30  # per user per hour
GEMINI_USER_RATE_LIMIT=60  # per user per hour
GROQ_USER_RATE_LIMIT=20  # per user per hour (free tier limit)

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# JWT Configuration
JWT_SECRET_KEY="your-jwt-secret-key-here"
JWT_ALGORITHM="HS256"
JWT_EXPIRATION_MINUTES=60
JWT_REFRESH_EXPIRATION_DAYS=7

# API Key Management
API_KEY_ROTATION_ENABLED=True
API_KEY_ROTATION_INTERVAL_DAYS=30

# Data Encryption
ENCRYPT_SENSITIVE_DATA=True
ENCRYPTION_KEY="your-encryption-key-here"

# =============================================================================
# LOGGING & MONITORING
# =============================================================================

# Logging Configuration
LOG_LEVEL="INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT="json"  # json, text
LOG_FILE="./logs/jobwise.log"
LOG_ROTATION_SIZE="10MB"
LOG_RETENTION_DAYS=30

# Metrics Configuration
PROMETHEUS_ENABLED=True
PROMETHEUS_PORT=8001
METRICS_COLLECTION_INTERVAL=10  # seconds

# Sentry Error Tracking
SENTRY_DSN="your-sentry-dsn-here"
SENTRY_ENVIRONMENT="development"
SENTRY_SAMPLE_RATE=1.0

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Feature Toggle Configuration
ENABLE_COVER_LETTER_GENERATION=True
ENABLE_MULTIPLE_RESUME_FORMATS=True
ENABLE_REAL_TIME_COLLABORATION=False
ENABLE_AI_COACHING=False
ENABLE_PREMIUM_FEATURES=False

# Experimental Features
ENABLE_EXPERIMENTAL_PROVIDERS=False
ENABLE_A_B_TESTING=False
ENABLE_ADVANCED_ANALYTICS=True

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Development Settings
DEV_MODE=True
DEV_AUTO_RELOAD=True
DEV_MOCK_EXTERNAL_APIS=True
DEV_BYPASS_RATE_LIMITS=True
DEV_ENABLE_DEBUG_ENDPOINTS=True

# Testing Configuration
TEST_DATABASE_URL="sqlite:///:memory:"
TEST_MOCK_ALL_PROVIDERS=True
TEST_PARALLEL_EXECUTION=False